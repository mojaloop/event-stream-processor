version: "2.2"

services:

  # setup:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
  
  es01:
    # depends_on:
    #   setup:
    #     condition: service_healthy
    image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
    volumes:
      # - certs:/usr/share/elasticsearch/config/certs
      - esdata01:/usr/share/elasticsearch/data
    ports:
      - ${ES_PORT}:9200
    environment:
      - node.name=es01
      - cluster.name=${CLUSTER_NAME}
      - cluster.initial_master_nodes=es01
      - bootstrap.memory_lock=true
      ## Password config, enable xpac security
      # - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      ## xpack security
      - xpack.security.enabled=false
      - xpack.security.transport.ssl.enabled=false
    mem_limit: ${MEM_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s http://localhost:9200",
        ]
        ## Required if certificates are enabled
        # [
        #   "CMD-SHELL",
        #   "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
        # ]
      interval: 10s
      timeout: 10s
      retries: 120

  kibana:
    depends_on:
      es01:
        condition: service_healthy
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
    volumes:
      # - certs:/usr/share/kibana/config/certs
      - kibanadata:/usr/share/kibana/data
    ports:
      - ${KIBANA_PORT}:5601
    environment:
      - SERVERNAME=kibana
      - ELASTICSEARCH_HOSTS=http://es01:9200
      # - ELASTICSEARCH_USERNAME=kibana_system
      # - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
      # - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
    mem_limit: ${MEM_LIMIT}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  apm-server:
    depends_on:
      kibana:
        condition: service_healthy
    image: docker.elastic.co/apm/apm-server:${STACK_VERSION}
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    volumes:
      - ./configs/apm-server.docker.yml:/usr/share/apm-server/apm-server.yml
    ports:
      - ${APM_PORT}:8200
    command: >
      apm-server -e
        -E apm-server.rum.enabled=false
        -E apm-server.auth.anonymous.enabled=true
        -E output.elasticsearch.hosts=["es01:9200"]
        -E apm-server.kibana.enabled=false
    # -E apm-server.rum.enabled=true
    # -E apm-server.kibana.enabled=true
    # -E apm-server.kibana.protocol=http
    # -E apm-server.kibana.host=http://kibana:5601
    # -E setup.template.settings.index.number_of_replicas=0
    # -E setup.kibana.host=http://kibana:5601
    # -E apm-server.kibana.username=elastic
    # -E apm-server.kibana.password=elastic
    # -E apm-server.kibana.host=http://kibana:5601
    # -E output.elasticsearch.hosts=["es01:9200"]
    # -E output.elasticsearch.username=elastic
    # -E output.elasticsearch.password=elastic
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/

  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    # Disable logging as it is far too verbose for debugging locally
    logging:
      driver: none
    ports:
      - "${ZOOKEEPER_PORT}:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    # Disable logging as it is far too verbose for debugging locally
    logging:
      driver: none
    ports:
    # To learn about configuring Kafka for access across networks see
    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - "${KAFKA_PORT}:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENERS: LISTENER_DOCKER://kafka:29092,LISTENER_HOST://kafka:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER://kafka:29092,LISTENER_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER:PLAINTEXT,LISTENER_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
    healthcheck:
      test: ["CMD" ,"kafka-broker-api-versions","--bootstrap-server","kafka:29092"]
      timeout: 20s
      retries: 10
      start_period: 40s
      interval: 30s

  kowl:
    image: quay.io/cloudhut/kowl:v1.4.0
    deploy:
      replicas: 1
    restart: on-failure
    hostname: kowl
    ports:
    - "${KOWL_PORT}:8080"
    environment:
      - KAFKA_BROKERS=kafka:29092
    depends_on:
      - kafka

volumes:
  ## Required if certs are enabled
  # certs:
  #   driver: local
  esdata01:
    driver: local
  kibanadata:
    driver: local